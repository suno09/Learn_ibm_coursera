{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/concrete_crack_images_for_classification.zip -P ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip -q  concrete_crack_images_for_classification.zip -d  ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install pytorch=1.6.0 torchvision cudatoolkit=10.2 -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from torch import optim \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self,transform=None,train=True):\n",
    "        directory=\"data\"\n",
    "        positive=\"Positive\"\n",
    "        negative=\"Negative\"\n",
    "\n",
    "        positive_file_path=os.path.join(directory,positive)\n",
    "        negative_file_path=os.path.join(directory,negative)\n",
    "        positive_files=[os.path.join(positive_file_path,file) for file in  os.listdir(positive_file_path) if file.endswith(\".jpg\")]\n",
    "        positive_files.sort()\n",
    "        negative_files=[os.path.join(negative_file_path,file) for file in  os.listdir(negative_file_path) if file.endswith(\".jpg\")]\n",
    "        negative_files.sort()\n",
    "        number_of_samples=len(positive_files)+len(negative_files)\n",
    "        self.all_files=[None]*number_of_samples\n",
    "        self.all_files[::2]=positive_files\n",
    "        self.all_files[1::2]=negative_files \n",
    "        # The transform is goint to be used on image\n",
    "        self.transform = transform\n",
    "        #torch.LongTensor\n",
    "        self.Y=torch.zeros([number_of_samples]).type(torch.LongTensor)\n",
    "        self.Y[::2]=1\n",
    "        self.Y[1::2]=0\n",
    "        \n",
    "        if train:\n",
    "            self.all_files=self.all_files[:30000]\n",
    "            self.Y=self.Y[:30000]\n",
    "            self.len=len(self.all_files)\n",
    "        else:\n",
    "            self.all_files=self.all_files[30000:]\n",
    "            self.Y=self.Y[30000:]\n",
    "            self.len=len(self.all_files)    \n",
    "       \n",
    "    # Get the length\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    # Getter\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        \n",
    "        image=Image.open(self.all_files[idx])\n",
    "        y=self.Y[idx]\n",
    "          \n",
    "        \n",
    "        # If there is any transform method, apply it onto the image\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "# transforms.ToTensor()\n",
    "#transforms.Normalize(mean, std)\n",
    "#transforms.Compose([])\n",
    "\n",
    "transform =transforms.Compose([ transforms.ToTensor(), transforms.Normalize(mean, std)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train=Dataset(transform=transform,train=True)\n",
    "dataset_val=Dataset(transform=transform,train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 227, 227])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154587"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_of_image=3*227*227\n",
    "size_of_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1bff6105918>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change last output layer of resnet18 to 2 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "model.fc = nn.Linear(512, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=2, bias=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(dataset_train, batch_size=1000)\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 30000\n",
    "n_test = 10000\n",
    "n_epochs = 5\n",
    "loss_list = []\n",
    "accuracy_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "epoch 1 train 1 / 30\n",
      "epoch 1 train 2 / 30\n",
      "epoch 1 train 3 / 30\n",
      "epoch 1 train 4 / 30\n",
      "epoch 1 train 5 / 30\n",
      "epoch 1 train 6 / 30\n",
      "epoch 1 train 7 / 30\n",
      "epoch 1 train 8 / 30\n",
      "epoch 1 train 9 / 30\n",
      "epoch 1 train 10 / 30\n",
      "epoch 1 train 11 / 30\n",
      "epoch 1 train 12 / 30\n",
      "epoch 1 train 13 / 30\n",
      "epoch 1 train 14 / 30\n",
      "epoch 1 train 15 / 30\n",
      "epoch 1 train 16 / 30\n",
      "epoch 1 train 17 / 30\n",
      "epoch 1 train 18 / 30\n",
      "epoch 1 train 19 / 30\n",
      "epoch 1 train 20 / 30\n",
      "epoch 1 train 21 / 30\n",
      "epoch 1 train 22 / 30\n",
      "epoch 1 train 23 / 30\n",
      "epoch 1 train 24 / 30\n",
      "epoch 1 train 25 / 30\n",
      "epoch 1 train 26 / 30\n",
      "epoch 1 train 27 / 30\n",
      "epoch 1 train 28 / 30\n",
      "epoch 1 train 29 / 30\n",
      "epoch 1 train 30 / 30\n",
      "epoch 1 val 1 / 10\n",
      "epoch 1 val 2 / 10\n",
      "epoch 1 val 3 / 10\n",
      "epoch 1 val 4 / 10\n",
      "epoch 1 val 5 / 10\n",
      "epoch 1 val 6 / 10\n",
      "epoch 1 val 7 / 10\n",
      "epoch 1 val 8 / 10\n",
      "epoch 1 val 9 / 10\n",
      "epoch 1 val 10 / 10\n",
      "\n",
      "epoch 2\n",
      "epoch 2 train 1 / 30\n",
      "epoch 2 train 2 / 30\n",
      "epoch 2 train 3 / 30\n",
      "epoch 2 train 4 / 30\n",
      "epoch 2 train 5 / 30\n",
      "epoch 2 train 6 / 30\n",
      "epoch 2 train 7 / 30\n",
      "epoch 2 train 8 / 30\n",
      "epoch 2 train 9 / 30\n",
      "epoch 2 train 10 / 30\n",
      "epoch 2 train 11 / 30\n",
      "epoch 2 train 12 / 30\n",
      "epoch 2 train 13 / 30\n",
      "epoch 2 train 14 / 30\n",
      "epoch 2 train 15 / 30\n",
      "epoch 2 train 16 / 30\n",
      "epoch 2 train 17 / 30\n",
      "epoch 2 train 18 / 30\n",
      "epoch 2 train 19 / 30\n",
      "epoch 2 train 20 / 30\n",
      "epoch 2 train 21 / 30\n",
      "epoch 2 train 22 / 30\n",
      "epoch 2 train 23 / 30\n",
      "epoch 2 train 24 / 30\n",
      "epoch 2 train 25 / 30\n",
      "epoch 2 train 26 / 30\n",
      "epoch 2 train 27 / 30\n",
      "epoch 2 train 28 / 30\n",
      "epoch 2 train 29 / 30\n",
      "epoch 2 train 30 / 30\n",
      "epoch 2 val 1 / 10\n",
      "epoch 2 val 2 / 10\n",
      "epoch 2 val 3 / 10\n",
      "epoch 2 val 4 / 10\n",
      "epoch 2 val 5 / 10\n",
      "epoch 2 val 6 / 10\n",
      "epoch 2 val 7 / 10\n",
      "epoch 2 val 8 / 10\n",
      "epoch 2 val 9 / 10\n",
      "epoch 2 val 10 / 10\n",
      "\n",
      "epoch 3\n",
      "epoch 3 train 1 / 30\n",
      "epoch 3 train 2 / 30\n",
      "epoch 3 train 3 / 30\n",
      "epoch 3 train 4 / 30\n",
      "epoch 3 train 5 / 30\n",
      "epoch 3 train 6 / 30\n",
      "epoch 3 train 7 / 30\n",
      "epoch 3 train 8 / 30\n",
      "epoch 3 train 9 / 30\n",
      "epoch 3 train 10 / 30\n",
      "epoch 3 train 11 / 30\n",
      "epoch 3 train 12 / 30\n",
      "epoch 3 train 13 / 30\n",
      "epoch 3 train 14 / 30\n",
      "epoch 3 train 15 / 30\n",
      "epoch 3 train 16 / 30\n",
      "epoch 3 train 17 / 30\n",
      "epoch 3 train 18 / 30\n",
      "epoch 3 train 19 / 30\n",
      "epoch 3 train 20 / 30\n",
      "epoch 3 train 21 / 30\n",
      "epoch 3 train 22 / 30\n",
      "epoch 3 train 23 / 30\n",
      "epoch 3 train 24 / 30\n",
      "epoch 3 train 25 / 30\n",
      "epoch 3 train 26 / 30\n",
      "epoch 3 train 27 / 30\n",
      "epoch 3 train 28 / 30\n",
      "epoch 3 train 29 / 30\n",
      "epoch 3 train 30 / 30\n",
      "epoch 3 val 1 / 10\n",
      "epoch 3 val 2 / 10\n",
      "epoch 3 val 3 / 10\n",
      "epoch 3 val 4 / 10\n",
      "epoch 3 val 5 / 10\n",
      "epoch 3 val 6 / 10\n",
      "epoch 3 val 7 / 10\n",
      "epoch 3 val 8 / 10\n",
      "epoch 3 val 9 / 10\n",
      "epoch 3 val 10 / 10\n",
      "\n",
      "epoch 4\n",
      "epoch 4 train 1 / 30\n",
      "epoch 4 train 2 / 30\n",
      "epoch 4 train 3 / 30\n",
      "epoch 4 train 4 / 30\n",
      "epoch 4 train 5 / 30\n",
      "epoch 4 train 6 / 30\n",
      "epoch 4 train 7 / 30\n",
      "epoch 4 train 8 / 30\n",
      "epoch 4 train 9 / 30\n",
      "epoch 4 train 10 / 30\n",
      "epoch 4 train 11 / 30\n",
      "epoch 4 train 12 / 30\n",
      "epoch 4 train 13 / 30\n",
      "epoch 4 train 14 / 30\n",
      "epoch 4 train 15 / 30\n",
      "epoch 4 train 16 / 30\n",
      "epoch 4 train 17 / 30\n",
      "epoch 4 train 18 / 30\n",
      "epoch 4 train 19 / 30\n",
      "epoch 4 train 20 / 30\n",
      "epoch 4 train 21 / 30\n",
      "epoch 4 train 22 / 30\n",
      "epoch 4 train 23 / 30\n",
      "epoch 4 train 24 / 30\n",
      "epoch 4 train 25 / 30\n",
      "epoch 4 train 26 / 30\n",
      "epoch 4 train 27 / 30\n",
      "epoch 4 train 28 / 30\n",
      "epoch 4 train 29 / 30\n",
      "epoch 4 train 30 / 30\n",
      "epoch 4 val 1 / 10\n",
      "epoch 4 val 2 / 10\n",
      "epoch 4 val 3 / 10\n",
      "epoch 4 val 4 / 10\n",
      "epoch 4 val 5 / 10\n",
      "epoch 4 val 6 / 10\n",
      "epoch 4 val 7 / 10\n",
      "epoch 4 val 8 / 10\n",
      "epoch 4 val 9 / 10\n",
      "epoch 4 val 10 / 10\n",
      "\n",
      "epoch 5\n",
      "epoch 5 train 1 / 30\n",
      "epoch 5 train 2 / 30\n",
      "epoch 5 train 3 / 30\n",
      "epoch 5 train 4 / 30\n",
      "epoch 5 train 5 / 30\n",
      "epoch 5 train 6 / 30\n",
      "epoch 5 train 7 / 30\n",
      "epoch 5 train 8 / 30\n",
      "epoch 5 train 9 / 30\n",
      "epoch 5 train 10 / 30\n",
      "epoch 5 train 11 / 30\n",
      "epoch 5 train 12 / 30\n",
      "epoch 5 train 13 / 30\n",
      "epoch 5 train 14 / 30\n",
      "epoch 5 train 15 / 30\n",
      "epoch 5 train 16 / 30\n",
      "epoch 5 train 17 / 30\n",
      "epoch 5 train 18 / 30\n",
      "epoch 5 train 19 / 30\n",
      "epoch 5 train 20 / 30\n",
      "epoch 5 train 21 / 30\n",
      "epoch 5 train 22 / 30\n",
      "epoch 5 train 23 / 30\n",
      "epoch 5 train 24 / 30\n",
      "epoch 5 train 25 / 30\n",
      "epoch 5 train 26 / 30\n",
      "epoch 5 train 27 / 30\n",
      "epoch 5 train 28 / 30\n",
      "epoch 5 train 29 / 30\n",
      "epoch 5 train 30 / 30\n",
      "epoch 5 val 1 / 10\n",
      "epoch 5 val 2 / 10\n",
      "epoch 5 val 3 / 10\n",
      "epoch 5 val 4 / 10\n",
      "epoch 5 val 5 / 10\n",
      "epoch 5 val 6 / 10\n",
      "epoch 5 val 7 / 10\n",
      "epoch 5 val 8 / 10\n",
      "epoch 5 val 9 / 10\n",
      "epoch 5 val 10 / 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    print('epoch', (epoch + 1))\n",
    "    loss_sublist = []\n",
    "    i = 1\n",
    "    model.train()\n",
    "    for x, y in dataloader_train:\n",
    "        print('epoch', (epoch+1), 'train', i, '/ 30')\n",
    "        i += 1\n",
    "        optimizer.zero_grad()\n",
    "        z = model(x)\n",
    "        loss = criterion(z, y)\n",
    "        loss_sublist.append(loss.data.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    loss_list.append(np.mean(loss_sublist))\n",
    "    \n",
    "    correct = 0\n",
    "    i = 1\n",
    "    model.eval()\n",
    "    for x_test, y_test in dataloader_val:\n",
    "        print('epoch', (epoch+1), 'val', i, '/ 10')\n",
    "        i += 1\n",
    "        z = model(x_test)\n",
    "        _, y_hat = torch.max(z.data, 1)\n",
    "        correct += (y_hat == y_test).sum().item()\n",
    "    accuracy = correct / n_test\n",
    "    accuracy_list.append(accuracy)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1bf8341b7f0>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(loss_list), 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy : 99.014000 %\n"
     ]
    }
   ],
   "source": [
    "print('The accuracy : %f %%' % (np.mean(accuracy_list) * 100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'criterion': criterion,\n",
    "            }, 'model_resnet18.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get the first four misclassified samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False,  True, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False,  True, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False,  True, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False,  True, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False])\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/57570043/filter-data-in-pytorch-tensor\n",
    "misclass = []\n",
    "model.eval()\n",
    "i = 1\n",
    "\n",
    "for x_test, y_test in dataloader_val:\n",
    "    print(i)\n",
    "    z = model(x_test)\n",
    "    _, y_hat = torch.max(z.data, 1)\n",
    "    print(y_hat != y_test)\n",
    "    if (y_hat == y_test).sum().item() == 0:\n",
    "        print(y_hat)\n",
    "        misclass.append((i, y_hat, y_test))\n",
    "    i += 1\n",
    "    if misclass.__len__() == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "model.fc = nn.Linear(512, 2)\n",
    "#\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.1)\n",
    "#\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#\n",
    "checkpoint = torch.load('model_resnet18.model')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# epoch = checkpoint['epoch']\n",
    "loss = checkpoint['criterion']\n",
    "\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
